{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install semantic-kernel -U\n",
    "! pip install qdrant_client -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from dotenv import load_dotenv\n",
    "import semantic_kernel.connectors.ai.open_ai as skaoai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sk.Kernel()\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.add_chat_service(\"azure_chat_competion_service\", skaoai.AzureChatCompletion(\"gpt-35-turbo\",endpoint,api_key=api_key,api_version = \"2023-07-01-preview\"))\n",
    "\n",
    "\n",
    "kernel.add_text_embedding_generation_service(\n",
    "        \"embeddings_services\", skaoai.AzureTextEmbedding(\"text-embedding-ada-002\", endpoint,api_key=api_key,api_version = \"2023-07-01-preview\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_plugin = \"./plugins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_plugin = kernel.import_semantic_skill_from_directory(base_plugin , \"FilePlugin\")\n",
    "answer_plugin = kernel.import_semantic_skill_from_directory(base_plugin , \"AnswerPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_files = os.listdir(\"./data/notes\")\n",
    "transcrips_files = os.listdir(\"./data/transcripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kblist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in nodes_files:\n",
    "    file = open(\"./data/notes/\"+f, \"r\") \n",
    "    content = file.read()\n",
    "    notesFunc = files_plugin[\"Notes\"]\n",
    "    result = notesFunc(content)\n",
    "    mdcontent = result.result.replace(\"```json\",\"\").replace(\"```\",\"\")\n",
    "    json_result = json.loads(mdcontent)\n",
    "    kblist.append(json_result)\n",
    "    file.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in transcrips_files:\n",
    "    file = open(\"./data/transcripts/\"+f, \"r\") \n",
    "    content = file.read()\n",
    "    transcripsFunc = files_plugin[\"Transcrips\"]\n",
    "    result = transcripsFunc(content)\n",
    "    txtcontent = result.result.replace(\"```json\",\"\").replace(\"```\",\"\")\n",
    "    json_result = json.loads(txtcontent)\n",
    "    for item in json_result:\n",
    "        kblist.append(item)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vectordb = 'aboutMLKBDemoDemo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from semantic_kernel.connectors.memory.qdrant import QdrantMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_store = QdrantMemoryStore(vector_size=1536, url=\"http://localhost\",port=6333)\n",
    "await qdrant_store.create_collection_async(base_vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.register_memory_store(memory_store=qdrant_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in kblist:\n",
    "    content = item[\"kb\"] + ' - ' + item[\"content\"]\n",
    "    id =str(uuid.uuid4())\n",
    "    await kernel.memory.save_information_async(base_vectordb, id=id, text=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"can you tell me what is different ML and AI\"\n",
    "\n",
    "memories = await kernel.memory.search_async(\n",
    "    base_vectordb, ask, limit=1, min_relevance_score=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ''\n",
    "for memory in memories:\n",
    "    print(f\"Top Result: {memory.text} with score {memory.relevance}\")\n",
    "    result = memory.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
